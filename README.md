# ğŸ§  OmniMind â€” Multimodal RAG + Agentic AI System

**OmniMind** is an open-source, local AI assistant that can **read your data, reason about it, and respond intelligently**.  
It unifies text, image, and audio ingestion with retrieval-augmented generation (RAG), a lightweight knowledge graph, tool use, and self-critique â€” all exposed through a FastAPI backend and a one-file React web chat UI.


## ğŸš€ Features

| Capability | Description |
|-------------|-------------|
| ğŸ“„ **Text / Image / Audio Ingestion** | Reads `.txt`, `.md`, `.jpg`, `.png`, `.mp3`, `.wav` into embeddings using Sentence-Transformers, CLIP, and Whisper. |
| ğŸ” **Vector Memory** | FAISS-based semantic search for relevant document chunks. |
| ğŸ§© **Knowledge Graph** | Extracts entities and relations (via spaCy) and stores them in a simple graph structure. |
| ğŸ’¬ **RAG Agent** | Retrieval-augmented generation that synthesizes grounded answers from evidence. |
| ğŸ§® **Tool Calling** | Extensible tool registry (e.g., built-in calculator). |
| ğŸ§  **Self-Critique** | Agent reviews its own answers and flags missing evidence. |
| ğŸŒ **FastAPI Server** | `/ingest`, `/query`, `/agent`, `/tools`, `/health` endpoints. |
| ğŸ’» **React Chat UI** | Clean, responsive front-end built with TailwindCSS + React 18 (CDN-based, no build tools). |
| ğŸ”’ **Runs Locally** | 100% offline â€” no external APIs required. |


## ğŸ§© Architecture Overview

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  User / Web UI     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ REST / JSON
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     FastAPI App    â”‚
                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â”‚ /ingest  /query    â”‚
                 â”‚ /agent   /tools    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         Agent / RAG Core           â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ Retriever (FAISS + CrossEncoder)   â”‚
         â”‚ Knowledge Graph (NetworkX)         â”‚
         â”‚ Tools (Calculator, etc.)           â”‚
         â”‚ Self-Critique & Evidence Synthesis â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Vector Store / Memory  â”‚
              â”‚   + Docstore + KG       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ—ï¸ Project Structure
omnimind/
â”œâ”€ omnimind/
â”‚  â”œâ”€ memory.py           # Vector memory (FAISS)
â”‚  â”œâ”€ ingest_text.py      # Text chunking
â”‚  â”œâ”€ ingest_image.py     # CLIP embeddings
â”‚  â”œâ”€ ingest_audio.py     # Whisper/Faster-Whisper transcription
â”‚  â”œâ”€ kg.py               # Knowledge graph builder
â”‚  â”œâ”€ retriever.py        # Hybrid retrieval + re-ranking
â”‚  â”œâ”€ rag.py              # Evidence synthesis
â”‚  â”œâ”€ agent.py            # Agent loop + tool use + self-critique
â”‚  â”œâ”€ tools/              # Tool registry and built-ins
â”‚  â”œâ”€ app.py              # FastAPI backend
â”‚  â””â”€ evaluate.py         # Retrieval / RAG evaluation harness
â”œâ”€ scripts/               # CLI scripts (ingest, query, etc.)
â”œâ”€ data/raw/              # Input files (.txt/.md/.jpg/.wav)
â”œâ”€ data/processed/        # Vector index, docstore, KG
â””â”€ web/index.html         # React chat UI

âš™ï¸ Setup
1ï¸âƒ£ Create and activate a virtual environment
python -m venv .venv
# PowerShell
.\.venv\Scripts\Activate.ps1
# or bash
source .venv/bin/activate

2ï¸âƒ£ Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
python -m spacy download en_core_web_sm


(For audio features: pip install faster-whisper ffmpeg-python and ensure ffmpeg is installed.)

ğŸ§¾ Configuration

Edit config.yaml to adjust:

model names (sentence-transformers/all-MiniLM-L6-v2, cross-encoder/ms-marco-MiniLM-L-6-v2)

chunk size / overlap

top-k retrieval

paths for data and models

â–¶ï¸ Usage
Ingest data
python scripts/ingest.py

Build knowledge graph
python scripts/build_kg.py

Ask a question (retrieval only)
python scripts/query.py "What is OmniMind?"

Run the full agent
python scripts/run_agent.py "Describe OmniMind."

Start the API server
uvicorn omnimind.app:app --reload


Visit http://127.0.0.1:8000/docs
 for interactive API docs.

ğŸ’» Web Chat UI

Serve the front-end:

cd web
python -m http.server 5500


Open http://127.0.0.1:5500

â†’ Ensure API base URL is http://127.0.0.1:8000
â†’ Click Ingest data then chat with your AI assistant.

ğŸ§® Example Output
Question: calc 3*(5+2)

Evidence considered:
- OmniMind is a multimodal RAG agent with a vector store and a knowledge graph.

Synthesis:
Based on the retrieved evidence, here is a concise answer:
OmniMind is a multimodal RAG agent with a vector store and a knowledge graph.
[TOOL=calculator] {'result': 21}

Critique: Looks consistent with retrieved evidence.
Sources:
- data/raw/sample.txt (rank=8.128)

ğŸ§° Extending OmniMind
Feature	How to add it
ğŸ”§ New Tools	Add functions in omnimind/tools/builtin.py and register in tool_registry.py.
ğŸ§  Better KG	Swap NetworkX for Neo4j and update kg.py.
ğŸ—£ï¸ Voice Assistant	Use Whisper for STT + pyttsx3 for TTS.
ğŸŒ Cloud Deployment	Containerize with Docker + run behind Nginx or Render.
ğŸ¤– Bigger Models	Change model names in config.yaml (e.g., BAAI/bge-small-en).
ğŸ“Š Evaluation

Create data/processed/eval_qa.jsonl:

{"query":"What is OmniMind?","answers":["OmniMind is a multimodal RAG agent"],"positive_ids":["<doc_id>"]}


Run:

python -m omnimind.evaluate --eval_jsonl data/processed/eval_qa.jsonl

ğŸ§­ Roadmap

 Add LLM-based answer synthesis (Phi-3, Mistral, etc.)

 Neo4j-powered Knowledge Graph

 Web Search Tool plugin

 Voice interface

 Docker + Hugging Face Space deployment

ğŸ“œ License

MIT License Â© 2025

ğŸ¤ Credits

Built with â¤ï¸ using:

PyTorch

Sentence-Transformers

FAISS

spaCy

FastAPI

React

TailwindCSS

âœ¨ Authorâ€™s Note

OmniMind was created to help you understand how AI systems actually work under the hood â€” not just call an API.
Itâ€™s a full end-to-end architecture: ingestion â†’ memory â†’ reasoning â†’ tools â†’ reflection â†’ interface.
Use it as your personal research assistant, or a foundation to build your own custom copilots.

## ğŸ“˜ To publish

omnimind/
â”œâ”€ omnimind/
â”œâ”€ scripts/
â”œâ”€ web/
â”œâ”€ data/
â”œâ”€ config.yaml
â”œâ”€ requirements.txt
â””â”€ README.md

2. Initialize Git & push to GitHub:
```bash
git init
git add .
git commit -m "Initial commit: OmniMind RAG agent"
git branch -M main
git remote add origin https://github.com/<yourusername>/OmniMind.git
git push -u origin main

